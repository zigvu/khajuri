
# in increasing level of severity: DEBUG, INFO, ERROR
log_level:                                  DEBUG

# Count to multiply with the number of cores available in machine
# if using fraction, will round down to nearest integer after multiplication
# Example: 16 core machine and 1.4 factor = 22 threads to run in parallel
multiple_of_cpu_count:                        1.0

# Sliding window configurations
sliding_window:
  is_test:                                    false
  folders:
    frame_output:                             frames
    patch_output:                             patches
    json_output:                              json
    levedb_output:                            leveldb
    video_output:                             videos
    numpy_output:                             numpy
  frame_density:                              5
  # Dimension of patches
  output_width:                               256
  output_height:                              256
  x_stride:
    - 32
    - 64
    - 64
    - 128
    - 128
  y_stride:
    - 16
    - 32
    - 64
    - 64
    - 128
  scaling:
    - 0.4
    - 0.7
    - 1.0
    - 1.3
    - 1.6

# Caffe input
caffe_input:
  model_file:                                 "/mnt/data/multiClass-10_wc14/training/0_seed/networkModels/caffe_logo_train_iter_5000"
  video_prototxt_file:                        "/mnt/data/multiClass-10_wc14/training/0_seed/prototxt/logo_video.prototxt"
  deploy_prototxt_file:                       "/mnt/data/multiClass-10_wc14/training/0_seed/prototxt/logo_deploy.prototxt"
  # number of frames to put in one leveldb
  num_frames_per_leveldb:                    50
  num_concurrent_leveldbs:                   2
  # leveldb might be maintained in TEMPFS - if exceed this size, pause leveldb creation
  # if want to ignore the size limit, set to zero
  max_leveldb_size_mb:                       10000
  # lmdb circular buffers - look at issue65 for setting these
  lmdb_buffer_max_size:                      6
  lmdb_buffer_min_size:                      4
  lmdb_num_frames_per_buffer:                1
  # frame number to start video processing on
  video_frame_number_start:                  1
  use_gpu:                                   true
  gpu_devices:                               
    - 0
    - 1
  save_video_heatmap:                        false
  compute_frame_curation:                    false
  run_caffe_postprocess_in_parallel:         false
  run_caffe:                                 true
  run_postprocess:                           false
  all_classes:
    - '0'
    - '1'
    - '2'
    - '3'
    - '4'
    - '5'
    - '6'
  background_classes:
    - '3'

# Post processing
post_processing:
  detector_threshold:                         0.8
  # Note: to avoid losing caffe scores permanently, `save_patch_scores = false` 
  # is ONLY considered when saving JSON after post-processing stage
  save_patch_scores:                          true
  # this uses the snappy library - to unzip a file from the command line
  # issue: python -m snappy -d <filename.snappy>
  compressed_json:                            false

# Curation
curation:
  # total patches/frames per class = num_of_sets * num_of_items_per_set
  num_of_sets:                                5
  num_of_items_per_set:                       100

# Cellroti
cellroti:
  # url to connect to cellroti - auth in env. vars.
  urls:
    get_detectables: 'localhost:3000/api/v1/data/detectables'
    post_results: 'localhost:3000/api/v1/data/videos'
  storage_selection: 'SOFTLAYER' # alternative is s3
  storage_location: 'somemachine.ip.com:port/write/to/Folder' # alternative is s3 bucket 'cellroti-data-production'
